{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f933a9d8",
   "metadata": {},
   "source": [
    "<div style=\"display:flex;\">\n",
    "<img alt=\"New Relic\" style=\"display:block;height:64px\" src=\"https://gitlab.com/softbutterfly/open-source/open-source-office/-/raw/master/banners/borderless/brands/new_relic.png\" />\n",
    "<img alt=\"SoftButterfly\" style=\"display:block;height:64px;margin-left:auto\" src=\"https://gitlab.com/softbutterfly/open-source/open-source-office/-/raw/master/banners/borderless/softbutterfly.png\" />\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a28a75b6",
   "metadata": {},
   "source": [
    "# New Relic Playground 6: Fetch Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "655bfc21",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdaaf35c",
   "metadata": {},
   "source": [
    "Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b12edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import multiprocessing\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from queue import Queue\n",
    "from threading import Thread"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e050909a",
   "metadata": {},
   "source": [
    "Third-party libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9fa02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from newrelic_sb_sdk.client import NewRelicGqlClient\n",
    "from newrelic_sb_sdk.graphql import nerdgraph\n",
    "from newrelic_sb_sdk.graphql.objects import RootMutationType, RootQueryType\n",
    "from newrelic_sb_sdk.utils.response import get_response_data, print_response\n",
    "from sgqlc.operation import Operation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c480b13",
   "metadata": {},
   "source": [
    "## Client setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a6959ec",
   "metadata": {},
   "source": [
    "To setup the client, first we need to open load the credentials from environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63fba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_file = \"../.env\"\n",
    "\n",
    "dotenv.load_dotenv(env_file)\n",
    "\n",
    "NEW_RELIC_USER_KEY = os.environ.get(\"NEW_RELIC_USER_KEY\", None)\n",
    "\n",
    "if NEW_RELIC_USER_KEY is None:\n",
    "    raise ValueError(\n",
    "        \"Environment variable NEW_RELIC_USER_KEY is not set.\",\n",
    "    )\n",
    "\n",
    "NEW_RELIC_ACCOUNT_ID = os.environ.get(\"NEW_RELIC_ACCOUNT_ID\", None)\n",
    "\n",
    "if NEW_RELIC_ACCOUNT_ID is None:\n",
    "    raise ValueError(\n",
    "        \"Environment variable NEW_RELIC_ACCOUNT_ID is not set.\",\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fa15937",
   "metadata": {},
   "source": [
    "With environment varaibles loaded, we can proceed to instantiate the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a5dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "newrelic = NewRelicGqlClient(new_relic_user_key=NEW_RELIC_USER_KEY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d25a62f",
   "metadata": {},
   "source": [
    "## Client testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "781a7eed",
   "metadata": {},
   "source": [
    "In order to use an test the client we need configure `query_type` and `mutation_type` for the `nerdgraph` schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b5da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nerdgraph.query_type = RootQueryType\n",
    "nerdgraph.mutation_type = RootMutationType"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00f0c690",
   "metadata": {},
   "source": [
    "For testing we will use a simple query in GraphQL to get the atttributes from our user\n",
    "\n",
    "```gql\n",
    "query {\n",
    "  actor {\n",
    "    user {\n",
    "      email\n",
    "      id\n",
    "      name\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "This query will be build from the `nerdgraph` schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9193b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare an operation from the `query_type` in `nerdgraph`\n",
    "operation = Operation(nerdgraph.query_type)\n",
    "\n",
    "# Get the fields `id`, `email`, `name` from the `user` entity inside\n",
    "# `actor`\n",
    "operation.actor.user.__fields__(\"id\", \"email\", \"name\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cfd3010",
   "metadata": {},
   "source": [
    "This operation can be transformed into a GraphQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0433b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = operation.__to_graphql__()\n",
    "print(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0380ff57",
   "metadata": {},
   "source": [
    "And this query is the one we send to be executed by our client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f8f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = newrelic.execute(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfef11f2",
   "metadata": {},
   "source": [
    "The response data obtained is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b9863",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_response(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1eb9922",
   "metadata": {},
   "source": [
    "We can also use the raw query directly written by hand. For this is recomendable to use the `build_query` method in order to get a clean query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c8b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = newrelic.build_query(\n",
    "    \"\"\"\n",
    "        {\n",
    "            actor {\n",
    "                user {\n",
    "                    email\n",
    "                    name\n",
    "                    id\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c10313cd",
   "metadata": {},
   "source": [
    "And execute directly, as in the previous execution, with the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5109de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = newrelic.execute(query)\n",
    "print_response(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e458d995",
   "metadata": {},
   "source": [
    "## Playground area"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83829036-c4e3-4356-8c5e-f6856a18ae97",
   "metadata": {},
   "source": [
    "## Data extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a492ad78",
   "metadata": {},
   "source": [
    "### The case of study and its parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d573248-a750-4015-8a48-6519aa8a137d",
   "metadata": {},
   "source": [
    "Suppose we need to get logs from a specific application on a certain day. Our NRQL query will look like this"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61a38625-2c45-41d5-8b50-df232b255b22",
   "metadata": {},
   "source": [
    "```sql\n",
    "FROM\n",
    "    Log\n",
    "SELECT\n",
    "    timestmap, message\n",
    "WHERE\n",
    "    `entity.name` = 'MyApplicationName'\n",
    "LIMIT\n",
    "    MAX \n",
    "SINCE\n",
    "    '2023-01-01 00:00'\n",
    "UNTIL\n",
    "    '2023-01-02 00:00'\n",
    "WITH TIMEZONE\n",
    "    'America/Lima'\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "758adf48-19a6-4dc8-9d08-0bb9d75eab51",
   "metadata": {},
   "source": [
    "You can change the clauses values according to your interests, and then forma them in the following way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a6808",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_TYPE = \"Log\"\n",
    "SELECT_FIELDS_TEMPLATE = \"`timestamp`, `message`\"\n",
    "WHERE_TEMPLATE = \"WHERE `entity.name` = 'MyApplicationName'\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "855a1a01-d7dc-46ae-b315-3e1d2b2d32f2",
   "metadata": {},
   "source": [
    "Aditionally, consider defining the following variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00022620-51af-4ffe-93fd-8d2e39e99915",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT_COUNT_TEMPLATE = \"count(*)\"\n",
    "timeseries_template = \"TIMESERIES 1 hour\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21d92f82-52e4-4f7c-890e-96593ec8aeea",
   "metadata": {},
   "source": [
    "This variables can allow us to transform the previous NRQL query into"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb943fb4-5ba1-4afa-955d-af41218c8be2",
   "metadata": {},
   "source": [
    "```sql\n",
    "FROM\n",
    "    Log\n",
    "SELECT\n",
    "    count(*)\n",
    "WHERE\n",
    "    `entity.name` = 'MyApplicationName'\n",
    "LIMIT\n",
    "    MAX \n",
    "SINCE\n",
    "    '2023-01-01 00:00'\n",
    "UNTIL\n",
    "    '2023-01-02 00:00'\n",
    "WITH TIMEZONE\n",
    "    'America/Lima'\n",
    "TIMESERIES\n",
    "    1 hour\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2884685a-d033-4a71-aa3e-db9c4ddca0e6",
   "metadata": {},
   "source": [
    "to get the time distribution of our data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ce8a78c-f6d2-4c6b-b384-7b99b2cf4048",
   "metadata": {},
   "source": [
    "Finally we can define the time range variables to get our data and a file description to refer what we are getting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820b293f-7de4-4cca-a0e3-7a129856b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME = datetime(2023, 1, 1, 0, 0, 0)  # From 1/1/2023 at 00:00\n",
    "END_TIME = datetime(2023, 1, 2, 0, 0, 0)  # Until 2/1/2023 at 00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea0756c-ef48-49e6-aaa9-e5f3f7bf6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DESCRIPTION = \"my_application_name_logs\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e336a34-9471-4de3-92bd-d90f4812fb2d",
   "metadata": {},
   "source": [
    "### The data fetch function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7e2e772-c03a-48ab-b8de-00a5d39a1b46",
   "metadata": {},
   "source": [
    "To fetch data we will use the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(*, template, params, start_time, end_time, key_path):\n",
    "    query = newrelic.build_query(  # pylint: disable=redefined-outer-name\n",
    "        template,\n",
    "        params={\n",
    "            **params,\n",
    "            \"start_time\": start_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"end_time\": end_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    data = None  # pylint: disable=redefined-outer-name\n",
    "    response = None  # pylint: disable=redefined-outer-name\n",
    "\n",
    "    try:\n",
    "        response = newrelic.execute(query)\n",
    "        data = get_response_data(response, key_path=key_path)\n",
    "    except Exception as e:  # pylint: disable=broad-except\n",
    "        print(\n",
    "            f\"Error fetching data from New Relic since {start_time} \"\n",
    "            + f\"to {end_time}: {e}\"\n",
    "        )\n",
    "        if response is not None:\n",
    "            print_response(response)\n",
    "\n",
    "        print(\"Retry again in 1 second\")\n",
    "        time.sleep(1)\n",
    "\n",
    "        return fetch_data(\n",
    "            template=template,\n",
    "            params=params,\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            key_path=key_path,\n",
    "        )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41e5f5da",
   "metadata": {},
   "source": [
    "### Counting data entries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2d2ab5b-4794-4bc5-89f8-56148dd93913",
   "metadata": {},
   "source": [
    "Using the variables from the previuos parts, we can define our query and get the ampount of Log entries present in the range of time of our interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850a741-867f-4b00-a43c-7904f0c388cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"\"\"\n",
    "    {\n",
    "        actor {\n",
    "            nrql(\n",
    "                query: \"FROM %(event_type)s SELECT %(select_template)s %(where_template)s SINCE '%(start_time)s' UNTIL '%(end_time)s' WITH TIMEZONE 'America/Lima' LIMIT MAX %(timeseries_template)s\",\n",
    "                accounts: %(account_id)s,\n",
    "                timeout: 50,\n",
    "            ) {\n",
    "                results\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "query_params = {\n",
    "    \"event_type\": EVENT_TYPE,\n",
    "    \"select_template\": SELECT_COUNT_TEMPLATE,\n",
    "    \"where_template\": WHERE_TEMPLATE,\n",
    "    \"timeseries_template\": \"\",\n",
    "    \"account_id\": NEW_RELIC_ACCOUNT_ID,\n",
    "}\n",
    "\n",
    "entries_count = fetch_data(\n",
    "    template=query_template,\n",
    "    params=query_params,\n",
    "    start_time=START_TIME,\n",
    "    end_time=END_TIME,\n",
    "    key_path=\"nrql:results:0:count\",\n",
    ")\n",
    "\n",
    "print(f\"Entries count: {entries_count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14f96e86",
   "metadata": {},
   "source": [
    "### Data distribution over time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20b10973-b6e8-4da8-91b8-09a7861a02ce",
   "metadata": {},
   "source": [
    "We can also look for data distribution over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943866d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"\"\"\n",
    "    {\n",
    "        actor {\n",
    "            nrql(\n",
    "                query: \"FROM %(event_type)s SELECT %(select_template)s %(where_template)s SINCE '%(start_time)s' UNTIL '%(end_time)s' WITH TIMEZONE 'America/Bogota' LIMIT MAX %(timeseries_template)s\",\n",
    "                accounts: %(account_id)s,\n",
    "                timeout: 50,\n",
    "            ) {\n",
    "                results\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "query_params = {\n",
    "    \"event_type\": EVENT_TYPE,\n",
    "    \"select_template\": SELECT_COUNT_TEMPLATE,\n",
    "    \"where_template\": WHERE_TEMPLATE,\n",
    "    \"timeseries_template\": timeseries_template,\n",
    "    \"account_id\": NEW_RELIC_ACCOUNT_ID,\n",
    "}\n",
    "\n",
    "results = fetch_data(\n",
    "    template=query_template,\n",
    "    params=query_params,\n",
    "    start_time=START_TIME,\n",
    "    end_time=END_TIME,\n",
    "    key_path=\"nrql:results\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e5e2617-680a-4afe-b991-5a97ecadf96f",
   "metadata": {},
   "source": [
    "And plot it here to saw how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dca0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = results[0][\"endTimeSeconds\"] - results[0][\"beginTimeSeconds\"]\n",
    "data = [\n",
    "    (\n",
    "        datetime.fromtimestamp(\n",
    "            (record[\"endTimeSeconds\"] + record[\"beginTimeSeconds\"]) // 2\n",
    "        ),\n",
    "        record[\"count\"],\n",
    "    )\n",
    "    for record in results\n",
    "]\n",
    "x, y = zip(*data)\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "figure_handler = plt.figure(figsize=(15, 5))\n",
    "axes_handler = figure_handler.add_subplot(111)\n",
    "axes_handler.plot(x, y, \"r-\")\n",
    "axes_handler.set_xlabel(\"Time\")\n",
    "axes_handler.set_ylabel(\"Count\")\n",
    "axes_handler.set_title(f\"{EVENT_TYPE} count\")\n",
    "axes_handler.grid(axis=\"both\", alpha=0.75)\n",
    "figure_handler.tight_layout()\n",
    "figure_handler.savefig(\n",
    "    f\"plot__{EVENT_TYPE}__{'_'.join(FILE_DESCRIPTION.split(' '))}\"\n",
    "    + f\"__{START_TIME:%Y%m%dT%H%M%S}__{END_TIME:%Y%m%dT%H%M%S}.png\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afb09647",
   "metadata": {},
   "source": [
    "### Data retrieval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "447c2e42-7e56-49ee-9432-2b4d3190b4d5",
   "metadata": {},
   "source": [
    "Due to the New Relic restriction, if we have more than 2000 entries in our time range, we need to break it into small parts and iterate over them until we get all the records. But keep in mind that there are some race conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5139a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wide_range_data(\n",
    "    *,\n",
    "    worker,\n",
    "    template,\n",
    "    params,\n",
    "    start_time,\n",
    "    end_time,\n",
    "    entries_count,  # pylint: disable=redefined-outer-name\n",
    "):\n",
    "    total_time = end_time - start_time\n",
    "    remaining_time = end_time - start_time\n",
    "\n",
    "    data = []  # pylint: disable=redefined-outer-name\n",
    "    data_df = None  # pylint: disable=redefined-outer-name\n",
    "\n",
    "    current_end_time = end_time\n",
    "\n",
    "    while current_end_time > start_time:\n",
    "        print(\n",
    "            f\"[Worker {worker.order}:{worker.job}] QUERY FROM \"\n",
    "            + f\"[{start_time.strftime('%Y-%m-%d %H:%M:%S')}] TO \"\n",
    "            + f\"[{current_end_time.strftime('%Y-%m-%d %H:%M:%S')}]\"\n",
    "        )\n",
    "\n",
    "        data = fetch_data(\n",
    "            template=template,\n",
    "            params=params,\n",
    "            start_time=start_time,\n",
    "            end_time=current_end_time,\n",
    "            key_path=\"nrql:results\",\n",
    "        )\n",
    "\n",
    "        if data is None or len(data) == 0:\n",
    "            current_end_time = start_time\n",
    "        else:\n",
    "            temp_df = pd.DataFrame(data)\n",
    "            temp_df[\"timestamp\"] = pd.to_datetime(\n",
    "                temp_df[\"timestamp\"],\n",
    "                unit=\"ms\",\n",
    "            )\n",
    "            temp_df = temp_df.sort_values(\n",
    "                \"timestamp\",\n",
    "                ascending=False,\n",
    "            ).reset_index(\n",
    "                drop=True,\n",
    "            )\n",
    "\n",
    "            if data_df is None:\n",
    "                data_df = temp_df\n",
    "\n",
    "            else:\n",
    "                data_df = pd.concat([temp_df, data_df], axis=0)\n",
    "\n",
    "            data_df = (\n",
    "                data_df.sort_values(\"timestamp\", ascending=False)\n",
    "                .reset_index(drop=True)\n",
    "                .drop_duplicates()\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"[Worker {worker.order}:{worker.job}] DATA FROM \"\n",
    "                + f\"[{start_time.strftime('%Y-%m-%d %H:%M:%S.%f')}] TO \"\n",
    "                + f\"[{current_end_time.strftime('%Y-%m-%d %H:%M:%S.%f')}]: \"\n",
    "                + f\"{data_df.shape[0]} records of {entries_count}\"\n",
    "            )\n",
    "\n",
    "            if data_df.shape[0] == entries_count:\n",
    "                current_end_time = start_time\n",
    "            else:\n",
    "                current_end_time = pd.to_datetime(\n",
    "                    data_df[\"timestamp\"].values[-1],\n",
    "                )\n",
    "                current_end_time = current_end_time + timedelta(\n",
    "                    microseconds=1000000 - current_end_time.microsecond\n",
    "                )\n",
    "                remaining_time = current_end_time - start_time\n",
    "\n",
    "            if remaining_time > total_time:\n",
    "                print(\"loop detected\")\n",
    "                break\n",
    "\n",
    "    return data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "545f8b44-2da1-4f74-b08c-e4c08a3d8e6d",
   "metadata": {},
   "source": [
    "We usually have tens or hundreds of thousands of logs for long periods, so to speed up the download of logs we can do it simultaneously. Fot this we need to define a `Worker` class which will handle the download jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker(Thread):\n",
    "    def __init__(self, *, queue, order):\n",
    "        Thread.__init__(self)\n",
    "        self.results = []\n",
    "        self.queue = queue\n",
    "        self.order = order\n",
    "        self.job = None\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            job, (start_time, end_time) = self.queue.get()\n",
    "\n",
    "            if job is None:\n",
    "                break\n",
    "\n",
    "            self.job = job\n",
    "\n",
    "            print(f\"[Worker {self.order}:{self.job}] Started\")\n",
    "            print(\n",
    "                f\"[Worker {self.order}:{self.job}] Getting data since \"\n",
    "                + f\"{start_time.strftime('%Y-%m-%d %H:%M:%S.%f')} until \"\n",
    "                + f\"{end_time.strftime('%Y-%m-%d %H:%M:%S.%f')}\"\n",
    "            )\n",
    "\n",
    "            query_template = \"\"  # pylint: disable=redefined-outer-name\n",
    "            query_params = None  # pylint: disable=redefined-outer-name\n",
    "\n",
    "            # -------------------------------------------------------------------------\n",
    "            # Start User modifications\n",
    "            # -------------------------------------------------------------------------\n",
    "            # Modify your query here\n",
    "            query_template = \"\"\"\n",
    "                {\n",
    "                    actor {\n",
    "                        nrql(\n",
    "                            query: \"FROM %(event_type)s SELECT %(select_template)s %(where_template)s SINCE '%(start_time)s' UNTIL '%(end_time)s' WITH TIMEZONE 'America/Bogota' LIMIT MAX %(timeseries_template)s\",\n",
    "                            accounts: %(account_id)s,\n",
    "                            timeout: 50,\n",
    "                        ) {\n",
    "                            results\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            \"\"\"\n",
    "\n",
    "            query_params = {\n",
    "                \"event_type\": EVENT_TYPE,\n",
    "                \"select_template\": SELECT_COUNT_TEMPLATE,\n",
    "                \"where_template\": WHERE_TEMPLATE,\n",
    "                \"timeseries_template\": \"\",\n",
    "                \"account_id\": NEW_RELIC_ACCOUNT_ID,\n",
    "            }\n",
    "            # -------------------------------------------------------------------------\n",
    "            # End User modifications\n",
    "            # -------------------------------------------------------------------------\n",
    "\n",
    "            # Get entries count\n",
    "            entries_count = fetch_data(  # pylint: disable=redefined-outer-name\n",
    "                template=query_template,\n",
    "                params=query_params,\n",
    "                start_time=start_time,\n",
    "                end_time=end_time,\n",
    "                key_path=\"nrql:results:0:count\",\n",
    "            )\n",
    "            print(\n",
    "                f\"[Worker {self.order}:{self.job}] Total entries count: {entries_count}\"\n",
    "            )\n",
    "\n",
    "            # -------------------------------------------------------------------------\n",
    "            # Start User modifications\n",
    "            # -------------------------------------------------------------------------\n",
    "            # Modify your query here\n",
    "            query_template = \"\"\"\n",
    "                {\n",
    "                    actor {\n",
    "                        nrql(\n",
    "                            query: \"FROM %(event_type)s SELECT %(select_template)s %(where_template)s SINCE '%(start_time)s' UNTIL '%(end_time)s' WITH TIMEZONE 'America/Bogota' LIMIT MAX %(timeseries_template)s\",\n",
    "                            accounts: %(account_id)s,\n",
    "                            timeout: 50,\n",
    "                        ) {\n",
    "                            results\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            \"\"\"\n",
    "\n",
    "            query_params = {\n",
    "                \"event_type\": EVENT_TYPE,\n",
    "                \"select_template\": SELECT_FIELDS_TEMPLATE,\n",
    "                \"where_template\": WHERE_TEMPLATE,\n",
    "                \"timeseries_template\": \"\",\n",
    "                \"account_id\": NEW_RELIC_ACCOUNT_ID,\n",
    "            }\n",
    "            # -------------------------------------------------------------------------\n",
    "            # End User modifications\n",
    "            # -------------------------------------------------------------------------\n",
    "            self.results.append(\n",
    "                fetch_wide_range_data(\n",
    "                    worker=self,\n",
    "                    template=query_template,\n",
    "                    params=query_params,\n",
    "                    start_time=start_time,\n",
    "                    end_time=end_time,\n",
    "                    entries_count=entries_count,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return self.results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05c8c93b-f182-46c2-9083-7aa625d7f61b",
   "metadata": {},
   "source": [
    "and a function to handle the time splitting task and the whole download process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00679581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_parallel_data_fetch(*, start_time, end_time, interval_duration):\n",
    "    timer = datetime.now()\n",
    "    intervals = range(\n",
    "        int(start_time.timestamp()),\n",
    "        int(end_time.timestamp() + interval_duration.total_seconds()),\n",
    "        int(interval_duration.total_seconds()),\n",
    "    )\n",
    "    intervals = [datetime.fromtimestamp(interval) for interval in intervals]\n",
    "    intervals = list(zip(intervals[0:-1], intervals[1:]))\n",
    "\n",
    "    queue = Queue()\n",
    "    empty_job = (None, (None, None))\n",
    "\n",
    "    workers = []\n",
    "    workers_count = min(multiprocessing.cpu_count(), len(intervals))\n",
    "\n",
    "    results = []  # pylint: disable=redefined-outer-name\n",
    "\n",
    "    for job in enumerate(intervals):\n",
    "        queue.put(job)\n",
    "\n",
    "    for _ in range(workers_count):\n",
    "        queue.put(empty_job)\n",
    "\n",
    "    for order in range(workers_count):\n",
    "        worker = Worker(order=order, queue=queue)\n",
    "        worker.start()\n",
    "        workers.append(worker)\n",
    "\n",
    "    for worker in workers:\n",
    "        worker.join()\n",
    "\n",
    "    for worker in workers:\n",
    "        results.append(worker.results)\n",
    "\n",
    "    print(\"Total executin time: \", datetime.now() - timer)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b2cdf6b-3c62-49ed-9f7d-c38e99418ca4",
   "metadata": {},
   "source": [
    "Once the above utilities are defined we can use them to download our data in wide time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d863d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDE_RANGE_START_TIME = datetime(2023, 1, 1, 0, 0, 0)  # From 1/1/2023 at 00:00\n",
    "WIDE_RANGE_END_TIME = datetime(2023, 2, 1, 0, 0, 0)  # Until 1/2/2023 at 00:00\n",
    "\n",
    "INTERVAL_DURATION = timedelta(seconds=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64063068",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"\"\"\n",
    "    {\n",
    "        actor {\n",
    "            nrql(\n",
    "                query: \"FROM %(event_type)s SELECT %(select_template)s %(where_template)s SINCE '%(start_time)s' UNTIL '%(end_time)s' WITH TIMEZONE 'America/Bogota' LIMIT MAX %(timeseries_template)s\",\n",
    "                accounts: %(account_id)s,\n",
    "                timeout: 50,\n",
    "            ) {\n",
    "                results\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "query_params = {\n",
    "    \"event_type\": EVENT_TYPE,\n",
    "    \"select_template\": SELECT_COUNT_TEMPLATE,\n",
    "    \"where_template\": WHERE_TEMPLATE,\n",
    "    \"timeseries_template\": \"\",\n",
    "    \"account_id\": NEW_RELIC_ACCOUNT_ID,\n",
    "}\n",
    "\n",
    "entries_count = fetch_data(\n",
    "    template=query_template,\n",
    "    params=query_params,\n",
    "    start_time=WIDE_RANGE_START_TIME,\n",
    "    end_time=WIDE_RANGE_END_TIME,\n",
    "    key_path=\"nrql:results:0:count\",\n",
    ")\n",
    "\n",
    "print(f\"Entries count: {entries_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5287f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = perform_parallel_data_fetch(\n",
    "    start_time=WIDE_RANGE_START_TIME,\n",
    "    end_time=WIDE_RANGE_END_TIME,\n",
    "    interval_duration=INTERVAL_DURATION,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e87a47bd",
   "metadata": {},
   "source": [
    "### Data saving"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85787962-f53a-44ca-9919-aa413711e2d4",
   "metadata": {},
   "source": [
    "Finally we can save our results in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f0b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat(\n",
    "    [result for result in itertools.chain(*results) if result is not None],\n",
    ")\n",
    "\n",
    "data_df = data_df.drop_duplicates()\n",
    "data_df = data_df.sort_values(by=\"timestamp\")\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40308c7-a605-4590-9189-2922209eb69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(\n",
    "    f\"{EVENT_TYPE}__{'_'.join(FILE_DESCRIPTION.split(' '))}__\"\n",
    "    + f\"{WIDE_RANGE_START_TIME:%Y%m%dT%H%M%S}__\"\n",
    "    + f\"{WIDE_RANGE_END_TIME:%Y%m%dT%H%M%S}.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f00ee-e3b2-4bd1-9988-29ae0370e143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d4dae0db91c8aee3899b7144d23e31f44f35f81cc4fe9420384fba90ad6fd08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
